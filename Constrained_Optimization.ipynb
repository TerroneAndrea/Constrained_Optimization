{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95955749",
   "metadata": {},
   "source": [
    "First: import the requested packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e5706703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import autograd as ag\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c009f80b",
   "metadata": {},
   "source": [
    "Define the function to be minimize\n",
    "\n",
    "f: $R^{N}$ --> $R$\n",
    "\n",
    "\\begin{aligned}\n",
    "&f(x)=-9 -8$x_{1}$ -6$x_{2}$ -4$x_{3}$ +2$x_{1}^{2}$ +2$x_{2}^{2}$+2$x_{1}x_{2}$+2$x_{1}x_{3}$,\n",
    "\\end{aligned}\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ea6f0be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=  3                                            \n",
    "\n",
    "def f(x):\n",
    "    return 9-8*x[0]-6*x[1]-4*x[2]+2*x[0]**2+2*x[1]**2+x[2]**2+2*x[0]*x[1]+2*x[0]*x[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870705a8",
   "metadata": {},
   "source": [
    "Define the inequality constraints functions ( the number of constraints is M, every constraints need to be in the form **g(x) <= 0**)\n",
    "\n",
    "g: $R^{N}$ --> $R^{M}$\n",
    "\n",
    "$g_{1}$(x)= -(3-$x_{1}$-$x_{2}$-2$x_{3}$)< 0  \n",
    "$g_{2}$(x)= -$x_{1}$<0  \n",
    "$g_{3}$(x)= -$x_{2}$<0  \n",
    "$g_{4}$(x)= -$x_{3}$<0 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "54a58ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ng = 4  # Number of inequality constraints                                                                              \n",
    "def gv(x): \n",
    "    g1= -(3-x[0]-x[1]-2*x[2])\n",
    "    g2= -(x[0]) \n",
    "    g3= -(x[1])\n",
    "    g4= -(x[2]) \n",
    "    \n",
    "    return ([g1,g2,g3,g4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58725f29",
   "metadata": {},
   "source": [
    "Define the equality constraints functions ( the number of constraints is L, every constraints need to be in the form h(x) = 0)\n",
    "(If there aren't equality constraints, just return 0)\n",
    "\n",
    "h: $R^{N}$ --> $R^{L}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6a0b7f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "nh = 0   # Number of equality constrains\n",
    "\n",
    "def hv(x):                                                                                             \n",
    "    \n",
    "    return np.array([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de318cfd",
   "metadata": {},
   "source": [
    "Now we define a the function that solves an unconstrained optimization problem. This function will be used in the Penalty Method. ( this function is an implementation of the Truncated-Newton-Method with Conjugate-Gradient search direction. ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9b317116",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ottnonvinc(f,x):\n",
    "    g = ag.grad(f)\n",
    "    h = ag.hessian(f)\n",
    "    g_toll = 10e-04\n",
    "\n",
    "    delta = 0.5\n",
    "    gamma = 10e-3\n",
    "    eps1 = 10e-4\n",
    "    eps2 = 10e-4\n",
    "\n",
    "    k=0\n",
    "    #CONJUGATE-GRADIENT\n",
    "    while np.linalg.norm(g(x,eps))> g_toll:\n",
    "        \n",
    "        \n",
    "        d=0\n",
    "        b=0\n",
    "        s= -g(x,eps)\n",
    "        if np.dot(np.dot(s,h(x,eps)),s)< eps1*(np.linalg.norm(s))**2:\n",
    "            d= -g(x,eps)\n",
    "        else:\n",
    "            a= -(np.dot((np.dot(h(x,eps),d)+g(x,eps)),s))/(np.dot(np.dot(s,h(x,eps)),s))\n",
    "            d= d+ a*s\n",
    "            while np.linalg.norm(np.dot(h(x,eps),d)+g(x,eps)) > (1/(k+1))*eps2*np.linalg.norm(g(x,eps)):\n",
    "                b= np.dot(np.dot((np.dot(h(x,eps),d)+g(x,eps)),h(x,eps)),s)/(np.dot(np.dot(s,h(x,eps)),s))\n",
    "                s = -(np.dot(h(x,eps),d)+g(x,eps)) + b*s\n",
    "                if np.dot(np.dot(s,h(x,eps)),s) < eps1*(np.linalg.norm(s))**2:\n",
    "                    break\n",
    "                else:\n",
    "                    a = -(np.dot((np.dot(h(x,eps),d)+g(x,eps)),s))/(np.dot(np.dot(s,h(x,eps)),s))\n",
    "                    d = d + a*s\n",
    "        #ARMIJO-CONDITION\n",
    "        armijo = 1\n",
    "        while f(x + armijo * d,eps) > f(x,eps) + gamma * armijo * (np.dot(g(x,eps), d)):\n",
    "            armijo = delta * armijo\n",
    "        x = x+ armijo*d\n",
    "        k+=1\n",
    "        #Consider to set some early stopping criteria\n",
    "        \n",
    "    return (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab3b0fd",
   "metadata": {},
   "source": [
    "Now we define the following functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fa07b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isfeasg(x):                            # is x feasible for g inequality constraints?\n",
    "    r = gv(x)\n",
    "    if max(r) > 10**-3:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def isfeash(x):                           # is x feasible for h equality constraints?\n",
    "    r = hv(x)\n",
    "    if np.linalg.norm(max(r)) > 10**-3:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def complementarity(x, lambd, ng):        # Complementarity of Lagrange multiplier and g\n",
    "    r = []\n",
    "    for i in range(ng):\n",
    "        r.append(lambd[i] * gv(x)[i])\n",
    "    for i in range(ng):\n",
    "        if np.linalg.norm(r[i]) > 10**-3:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def lambdpos(lambd):                 # positivity of lagrange multiplier\n",
    "    for i in range(ng):\n",
    "        if lambd[i] < -10**-3:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def Lagrangiana(x,lambd,mu):          # Lagrangian Function\n",
    "    l=f(x)\n",
    "    for i in range(ng):\n",
    "        l+= lambd[i]*gv(x)[i]\n",
    "    for i in range(nh):\n",
    "        l+= mu[i]*hv(x)[i]\n",
    "    return l\n",
    "\n",
    "def gradLagrangiana(x,lambd,mu):          # Gradient of Lagrangian Function\n",
    "    l= ag.grad(Lagrangiana)(x,lambd,mu)\n",
    "    for i in range(n):\n",
    "        if np.linalg.norm(l[i]) > 10**-3:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ca148b",
   "metadata": {},
   "source": [
    "Now we define the KKT conditions function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e4292682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iskkt(x, lambd, mu, ng):\n",
    "    if isfeasg(x) == True and isfeash(x) == True and complementarity(x, lambd, ng) == True and lambdpos(lambd) == True and gradLagrangiana(x,lambd,mu) == True :\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedb6ca8",
   "metadata": {},
   "source": [
    "Now we define the following functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d10144af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalit√†(x,eps):                         # The penalty function to be optimized by the unconstrained optimization algorithm in the Penalty Method\n",
    "    p=f(x)\n",
    "    for i in range(ng):\n",
    "        p += (1/eps)*(max(0,gv(x)[i]))**2\n",
    "    for i in range(nh):\n",
    "        p += (1/eps)*(hv(x)[i])**2\n",
    "    return p\n",
    "\n",
    "def PHI(x):                                 # this functions will be used to decrease eps in the Penalty Method\n",
    "    r=0\n",
    "    for i in range(ng):\n",
    "        r += (max(0,gv(x)[i]))**2\n",
    "    for i in range(nh):\n",
    "        r+= (hv(x)[i])**2\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ede5cb6",
   "metadata": {},
   "source": [
    "Defining the initial point x and other needed constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eea95e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0.5, 0.5, 0.5])                                                                                                            # DA CAMBIARE SEMPRE\n",
    "eps =  0.01  \n",
    "teta1= 0.5\n",
    "teta2= 0.9\n",
    "teta3= 0.05\n",
    "\n",
    "lambd= []\n",
    "for i in range(ng):\n",
    "    lambd.append(max(0,gv(x)[i]))\n",
    "lambd= (2/eps)*np.array(lambd)\n",
    "\n",
    "mu= []\n",
    "for i in range(nh):\n",
    "    mu.append(hv(x)[i])\n",
    "mu= (2/eps)*np.array(mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307d28bf",
   "metadata": {},
   "source": [
    "Finally we define the Main Penalty Method Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c22f4792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final point x: [1.33331637 0.77778464 0.44444955]\n",
      "Function value f(x): 0.11111108559760896\n",
      "\n",
      "\n",
      "Feasibility of g inequality constraints: True\n",
      "[1.1611482320095234e-07, -1.3333163658339622, -0.7777846406025195, -0.44444955483917076]\n",
      "Feasibility of h equality constraints: True\n",
      "[0]\n",
      "are lambda and g complementary?\n",
      "True\n",
      "are lambda positive?\n",
      "True\n",
      "[0.24693168 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "while iskkt(x,lambd,mu,ng) != True:\n",
    "    xprima= x\n",
    "    x= ottnonvinc(penalit√†,x)\n",
    "    is_decreased=0\n",
    "    if PHI(x)<= PHI(xprima)*teta1:\n",
    "        pass\n",
    "    else:\n",
    "        eps = eps*teta2\n",
    "        is_decreased=1\n",
    "        if eps<0.000001:\n",
    "            break\n",
    "    lambd = []\n",
    "    for i in range(ng):\n",
    "        lambd.append(max(0, gv(x)[i]))\n",
    "    lambd = (2 / eps) * np.array(lambd)\n",
    "    mu = []\n",
    "    for i in range(nh):\n",
    "        mu.append(hv(x)[i])\n",
    "    mu = (2 / eps) * np.array(mu)\n",
    "    if np.linalg.norm(xprima-x)<10**-10 and is_decreased!=1:\n",
    "\n",
    "        break\n",
    "\n",
    "print(\"final point x:\", x)\n",
    "print(\"Function value f(x):\", f(x))\n",
    "print(\"\\n\")\n",
    "print(\"Feasibility of g inequality constraints:\",isfeasg(x))\n",
    "print(gv(x))\n",
    "print(\"Feasibility of h equality constraints:\",isfeash(x))\n",
    "print(hv(x))\n",
    "print(\"are lambda and g complementary?\")\n",
    "print(complementarity(x,lambd,ng))\n",
    "print(\"are lambda positive?\")\n",
    "print(lambdpos(lambd))\n",
    "print(lambd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
