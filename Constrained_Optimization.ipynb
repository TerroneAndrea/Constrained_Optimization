{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95955749",
   "metadata": {},
   "source": [
    "First: import the requested packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "e5706703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import autograd as ag\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c009f80b",
   "metadata": {},
   "source": [
    "Define the function to be minimize\n",
    "\n",
    "f: $R^{N}$ --> $R$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "ea6f0be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=  2                                                 \n",
    "\n",
    "def f(x):\n",
    "    return x[0]**2+ x[1]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870705a8",
   "metadata": {},
   "source": [
    "Define the inequality constraints functions ( the number of constraints is M, every constraints need to be in the form **g(x) <= a**)\n",
    "\n",
    "g: $R^{N}$ --> $R^{M}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "54a58ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ng = 5  # Number of inequality constraints                                                                              \n",
    "def gv(x): \n",
    "    g1= 1- x[0]-x[1]\n",
    "    g2= 1- x[0]**2 -x[1]**2\n",
    "    g3= 9 - 9*x[0]**2 -x[1]**2\n",
    "    g4= x[1]-x[0]**2\n",
    "    g5= x[0]-x[1]**2\n",
    "    \n",
    "    return ([g1,g2,g3,g4,g5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58725f29",
   "metadata": {},
   "source": [
    "Define the equality constraints functions ( the number of constraints is L, every constraints need to be in the form h(x) = 0)\n",
    "\n",
    "h: $R^{N}$ --> $R^{L}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "6a0b7f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "nh = 0   # Number of equality constrains\n",
    "\n",
    "def hv(x):                                                                                             \n",
    "    h1= 0\n",
    "    h2= 0\n",
    "    \n",
    "    return np.array([h1,h2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de318cfd",
   "metadata": {},
   "source": [
    "Now we define a the function that solves an unconstrained optimization problem. This function will be used in the Penalty Method. ( this function is an implementation of the Truncated-Newton-Method with Conjugate-Gradient search direction. ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "9b317116",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ottnonvinc(f,x):\n",
    "    g = ag.grad(f)\n",
    "    h = ag.hessian(f)\n",
    "    g_toll = 10e-04\n",
    "\n",
    "    delta = 0.5\n",
    "    gamma = 10e-3\n",
    "    eps1 = 10e-4\n",
    "    eps2 = 10e-4\n",
    "\n",
    "    k=0\n",
    "    #CONJUGATE-GRADIENT\n",
    "    while np.linalg.norm(g(x,eps))> g_toll:\n",
    "        \n",
    "        \n",
    "        d=0\n",
    "        b=0\n",
    "        s= -g(x,eps)\n",
    "        if np.dot(np.dot(s,h(x,eps)),s)< eps1*(np.linalg.norm(s))**2:\n",
    "            d= -g(x,eps)\n",
    "        else:\n",
    "            a= -(np.dot((np.dot(h(x,eps),d)+g(x,eps)),s))/(np.dot(np.dot(s,h(x,eps)),s))\n",
    "            d= d+ a*s\n",
    "            while np.linalg.norm(np.dot(h(x,eps),d)+g(x,eps)) > (1/(k+1))*eps2*np.linalg.norm(g(x,eps)):\n",
    "                b= np.dot(np.dot((np.dot(h(x,eps),d)+g(x,eps)),h(x,eps)),s)/(np.dot(np.dot(s,h(x,eps)),s))\n",
    "                s = -(np.dot(h(x,eps),d)+g(x,eps)) + b*s\n",
    "                if np.dot(np.dot(s,h(x,eps)),s) < eps1*(np.linalg.norm(s))**2:\n",
    "                    break\n",
    "                else:\n",
    "                    a = -(np.dot((np.dot(h(x,eps),d)+g(x,eps)),s))/(np.dot(np.dot(s,h(x,eps)),s))\n",
    "                    d = d + a*s\n",
    "        #ARMIJO-CONDITION\n",
    "        armijo = 1\n",
    "        while f(x + armijo * d,eps) > f(x,eps) + gamma * armijo * (np.dot(g(x,eps), d)):\n",
    "            armijo = delta * armijo\n",
    "        x = x+ armijo*d\n",
    "        k+=1\n",
    "        #Consider to set some early stopping criteria\n",
    "            \n",
    "        \n",
    "    return (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab3b0fd",
   "metadata": {},
   "source": [
    "Now we define the following functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "fa07b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isfeasg(x):                            # is x feasible for g inequality constraints?\n",
    "    r = gv(x)\n",
    "    if max(r) > 10**-3:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def isfeash(x):                           # is x feasible for h equality constraints?\n",
    "    r = hv(x)\n",
    "    if np.linalg.norm(max(r)) > 10**-3:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def complementarity(x, lambd, ng):        # Complementarity of Lagrange multiplier and g\n",
    "    r = []\n",
    "    for i in range(ng):\n",
    "        r.append(lambd[i] * gv(x)[i])\n",
    "    for i in range(ng):\n",
    "        if np.linalg.norm(r[i]) > 10**-3:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def lambdpos(lambd):                 # positivity of lagrange multiplier\n",
    "    for i in range(ng):\n",
    "        if lambd[i] < -10**-3:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def Lagrangiana(x,lambd,mu):          # Lagrangian Function\n",
    "    l=f(x)\n",
    "    for i in range(ng):\n",
    "        l+= lambd[i]*gv(x)[i]\n",
    "    for i in range(nh):\n",
    "        l+= mu[i]*hv(x)[i]\n",
    "    return l\n",
    "\n",
    "def gradLagrangiana(x,lambd,mu):          # Gradient of Lagrangian Function\n",
    "    l= ag.grad(Lagrangiana)(x,lambd,mu)\n",
    "    for i in range(n):\n",
    "        if np.linalg.norm(l[i]) > 10**-3:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ca148b",
   "metadata": {},
   "source": [
    "Now we define the KKT conditions function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "e4292682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iskkt(x, lambd, mu, ng):\n",
    "    if isfeasg(x) == True and isfeash(x) == True and complementarity(x, lambd, ng) == True and lambdpos(lambd) == True and gradLagrangiana(x,lambd,mu) == True :\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedb6ca8",
   "metadata": {},
   "source": [
    "Now we define the following functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "d10144af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalità(x,eps):                         # The penalty function to be optimized by the unconstrained optimization algorithm in the Penalty Method\n",
    "    p=f(x)\n",
    "    for i in range(ng):\n",
    "        p += (1/eps)*(max(0,gv(x)[i]))**2\n",
    "    for i in range(nh):\n",
    "        p += (1/eps)*(hv(x)[i])**2\n",
    "    return p\n",
    "\n",
    "def PHI(x):                                 # this functions will be used to decrease eps in the Penalty Method\n",
    "    r=0\n",
    "    for i in range(ng):\n",
    "        r += (max(0,gv(x)[i]))**2\n",
    "    for i in range(nh):\n",
    "        r+= (hv(x)[i])**2\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ede5cb6",
   "metadata": {},
   "source": [
    "Defining the initial point x and other needed constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "eea95e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([22.3,0.5])                                                                                                             # DA CAMBIARE SEMPRE\n",
    "eps =  0.01  \n",
    "teta1= 0.5\n",
    "teta2= 0.9\n",
    "teta3= 0.05\n",
    "\n",
    "lambd= []\n",
    "for i in range(ng):\n",
    "    lambd.append(max(0,gv(x)[i]))\n",
    "lambd= (2/eps)*np.array(lambd)\n",
    "\n",
    "mu= []\n",
    "for i in range(nh):\n",
    "    mu.append(hv(x)[i])\n",
    "mu= (2/eps)*np.array(mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307d28bf",
   "metadata": {},
   "source": [
    "Finally we define the Main Penalty Method Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "c22f4792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final point: [0.99999896 0.99999896]\n",
      "Function value: 1.9999958201665569\n",
      "\n",
      "True\n",
      "[-0.9999979100821865, -0.9999958201665569, -0.9999791008327835, 1.0449578148330474e-06, 1.0449578148330474e-06]\n",
      "True\n",
      "True\n",
      "True\n",
      "[0.         0.         0.         2.22222471 2.22222471]\n"
     ]
    }
   ],
   "source": [
    "while iskkt(x,lambd,mu,ng) != True:\n",
    "    xprima= x\n",
    "    x= ottnonvinc(penalità,x)\n",
    "    is_decreased=0\n",
    "    if PHI(x)<= PHI(xprima)*teta1:\n",
    "        pass\n",
    "    else:\n",
    "        eps = eps*teta2\n",
    "        is_decreased=1\n",
    "        if eps<0.000001:\n",
    "            break\n",
    "    lambd = []\n",
    "    for i in range(ng):\n",
    "        lambd.append(max(0, gv(x)[i]))\n",
    "    lambd = (2 / eps) * np.array(lambd)\n",
    "    mu = []\n",
    "    for i in range(nh):\n",
    "        mu.append(hv(x)[i])\n",
    "    mu = (2 / eps) * np.array(mu)\n",
    "    if np.linalg.norm(xprima-x)<10**-10 and is_decreased!=1:\n",
    "\n",
    "        break\n",
    "\n",
    "print(\"final point:\", x)\n",
    "print(\"Function value:\", f(x))\n",
    "print(\"\")\n",
    "print(isfeasg(x))\n",
    "print(gv(x))\n",
    "print(isfeash(x))\n",
    "print(complementarity(x,lambd,ng))\n",
    "print(lambdpos(lambd))\n",
    "print(lambd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
